


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import mglearn
from sklearn.datasets import make_blobs
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import export_graphviz 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


mglearn.plots.plot_scaling()








 from sklearn.datasets import load_breast_cancer
 from sklearn.model_selection import train_test_split
 cancer = load_breast_cancer()
 X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,
 random_state=1)
 print(X_train.shape)
 print(X_test.shape)





from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()





scaler.fit(X_train)





 # transform data
X_train_scaled = scaler.transform(X_train)
 # print dataset properties before and after scaling
np.set_printoptions(suppress=True, precision=4) # 删去这个就是科学计数法的表现形式
print("transformed shape: {}".format(X_train_scaled.shape))

print("per-feature minimum before scaling:\n {}".format(X_train.min(axis=0)))

print("per-feature maximum before scaling:\n {}".format(X_train.max(axis=0)))
 
print("per-feature minimum after scaling:\n {}".format(X_train_scaled.min(axis=0)))

print("per-feature maximum after scaling:\n {}".format(X_train_scaled.max(axis=0)))








 # transform test data
 X_test_scaled = scaler.transform(X_test)
 # print test data properties after scaling
 print("per-feature minimum after scaling:\n{}".format(X_test_scaled.min(axis=0)))
 print("per-feature maximum after scaling:\n{}".format(X_test_scaled.max(axis=0)))








 from sklearn.datasets import make_blobs

 # make synthetic data (构造数据)
 X, _ = make_blobs(n_samples=50, centers=5, random_state=4, cluster_std=2)

 # split it into training and test sets
 X_train, X_test = train_test_split(X, random_state=5, test_size=.1)

 # plot the training and test sets
 fig, axes = plt.subplots(1, 3, figsize=(13, 4))
 axes[0].scatter(X_train[:, 0], X_train[:, 1],
 c=mglearn.cm2(0), label="Training set", s=60)
 axes[0].scatter(X_test[:, 0], X_test[:, 1], marker='^',
 c=mglearn.cm2(1), label="Test set", s=60)
 axes[0].legend(loc='upper left')
 axes[0].set_title("Original Data")
 
 # scale the data using MinMaxScaler
 scaler = MinMaxScaler()
 scaler.fit(X_train)
 X_train_scaled = scaler.transform(X_train)
 X_test_scaled = scaler.transform(X_test)

 # visualize the properly scaled data
 axes[1].scatter(X_train_scaled[:, 0], X_train_scaled[:, 1],
 c=mglearn.cm2(0), label="Training set", s=60)
 axes[1].scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], marker='^',
 c=mglearn.cm2(1), label="Test set", s=60)
 axes[1].set_title("Scaled Data")

 # rescale the test set separately（单独对测试集进行缩放）
 # so test set min is 0 and test set max is 1
 # DO NOT DO THIS! For illustration purposes only.
 test_scaler = MinMaxScaler()
 test_scaler.fit(X_test)
 X_test_scaled_badly = test_scaler.transform(X_test)

 # visualize wrongly scaled data
 axes[2].scatter(X_train_scaled[:, 0], X_train_scaled[:, 1],
 c=mglearn.cm2(0), label="training set", s=60)
 axes[2].scatter(X_test_scaled_badly[:, 0], X_test_scaled_badly[:, 1],
 marker='^', c=mglearn.cm2(1), label="test set", s=60)
 axes[2].set_title("Improperly Scaled Data")
 for ax in axes:
     ax.set_xlabel("Feature 0")
     ax.set_ylabel("Feature 1")











from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,
 random_state=0)
svm = SVC(C=100,kernel='rbf') # default is rbf
svm.fit(X_train, y_train)
print("Test set accuracy: {:.2f}".format(svm.score(X_test, y_test)))





 # preprocessing using 0-1 scaling
 scaler = MinMaxScaler()
 scaler.fit(X_train)
 X_train_scaled = scaler.transform(X_train)
 X_test_scaled = scaler.transform(X_test)

 # learning an SVM on the scaled training data
 svm.fit(X_train_scaled, y_train)

 # scoring on the scaled test set
 print("Scaled test set accuracy: {:.2f}".format(
 svm.score(X_test_scaled, y_test)))








 # preprocessing using zero mean and unit variance scaling
 from sklearn.preprocessing import StandardScaler
 scaler = StandardScaler()
 scaler.fit(X_train)
 X_train_scaled = scaler.transform(X_train)
 X_test_scaled = scaler.transform(X_test)

 # learning an SVM on the scaled training data
 svm.fit(X_train_scaled, y_train)
 
 # scoring on the scaled test set
 print("SVM test accuracy: {:.2f}".format(svm.score(X_test_scaled, y_test)))















